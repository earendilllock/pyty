#+STARTUP: overview
#+STARTUP: hidestars
#+OPTIONS: LaTeX:t
#+OPTIONS: toc:nil
#+LaTeX_CLASS: per-file-class
#+TITLE: Каноническая аппроксимация тензоров и ее реализация на Python
#+AUTHOR: Кузнецов М.А.
#+DATE: 
* LATEX OPTIONS 						   :noexport:
#+OPTIONS: toc:nil
** Packages
#+LATEX_HEADER: \usepackage[T2A]{fontenc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[english,russian]{babel}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{amsfonts,amsmath,amssymb}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{algorithmic} \usepackage[ruled]{algorithm}
#+LATEX_HEADER: \usepackage[unicode=true,plainpages=false]{hyperref}
#+LATEX_HEADER: \hypersetup{colorlinks=true,linkcolor=magenta,anchorcolor=magenta,urlcolor=blue,citecolor=blue}
** User-defined symbols
#+LATEX_HEADER: \def\A{\mathbf{A}}
#+LATEX_HEADER: \def\V{\mathbf{V}}
#+LATEX_HEADER: \def\B{\mathbf{B}}
#+LATEX_HEADER: \def\C{\mathbf{C}}
** GeometryTEX_HEADER: \usepackage[a4paper]{geometry}




   

 
   
* Введение
     
  Аппроксимация многомерных массивов играет важную роль в приложениях. Однако вместо заданного многомерного массива
часто нужно пользоваться его приближением, свойства которого известны, возможно. в отличие от заданного.
Такие аппроксимации удобно строить используя следующее представление многомерного массива (/тензора/)

 /Определение/
  
 Тензором A размерности $d$ назовем многомерный массив, элементы которого A(i_1,i_2,\ldots,i_d) имеют $d$ 
индексов.

 /Определение/

 Каноническим разложением многомерного массива (/тензора/) 
называется представление вида 

\begin{equation}\label{curs:eq1}
A(i_1,i_2,\ldots,i_d) = \sum_{\alpha=1}^r U_1(i_1,\alpha) U_2(i_2,\alpha) \ldots U_d(i_d,\alpha),
\end{equation}
где U_k называются /факторами/ канонического разложения, а $r$ --- каноническим рангом.

Уравнение \eqref{curs:eq1} является основным.

* Описание метода ALS
  Пусть задан тензор A_i,_j,_k , требуется приблизить его с помощью матриц 
U,V,W, таким образом:

\begin{equation}
A_{i_1,\ldots,i_d} \approx  \sum_{\alpha=1}^r U_1(i_1,\alpha) U_2(i_2,\alpha) \ldots U_d(i_d,\alpha),
\end{equation}

это выражение можно понимать в смысле наименьших квадратов
\begin{equation}
\parallel A_{i_1},_{\ldots},_{i_d}  -  \sum_{\alpha=1}^r U_1(i_1,\alpha) U_2(i_2,\alpha) \ldots U_d(i_d,\alpha), \sum_{\alpha=1}^r U_1(i_1,\alpha) U_2(i_2,\alpha) \ldots U_d(i_d,\alpha) \parallel ^2 =
 
\sum_{i_1,\ldots,i_d} (A_{i_1},_{\ldots},_{i_d} - \sum_{\alpha=1}^r U_1(i_1,\alpha) U_2(i_2,\alpha) \ldots U_d(i_d,\alpha))^2
\longrightarrow min
\end{equation}

Для упрощения рассчетных формул проведем построение метода отыскания минимума
для тензора размерности 3 (в $d$ -мерном случае рассуждения аналогичны)

Введем функционал F,
\begin{equation}
F=\sum_{i,j,k=1} (A_{i,j,k}-\sum_{\alpha=1}^r U_{i,\alpha}V_{j,\alpha}W_{k,\alpha})^2
\end{equation}

найдем частную производную функционала F по U_{\hat x, \hat \alpha} и приравняем его к 0
\begin{equation*}
\frac{\partial F}{\partial U_{\hat x, \hat \alpha}} = 
2 \sum_{i,j,k}(A_{i,j,k}-\sum_{\alpha} U_{i,\alpha}V_{j,\alpha}W_{k,\alpha})-
\sum_{\check \alpha} V_{j,\check \alpha}W_{k,\check \alpha} =0
\end{equation*}

\begin{equation*}
-\sum_{i,j,k,\check \alpha} A_{i,j,k} \delta_{i,\hat i} \delta_{\check\alpha, \hat\alpha}
V_{j,\check \alpha}W_{k,\check \alpha} +
\sum_{i,j,k,\alpha,\check \alpha} U_{i,\alpha}V_{j,\alpha}
\delta_{i,\hat i}\delta_{\check \alpha,\hat \alpha}
V_{j,\check \alpha}W_{k,\check \alpha}
\end{equation*}

\begin{equation*}
\sum_{j,k} A_{\hat i,j,k}V_{j, \hat \alpha}W_{k,\hat \alpha}=
\sum_{j,k,\alpha} U_{\hat i,\alpha}V_{j,\alpha}W_{k,\alpha}V_{j,\hat \alpha}
W_{k,\hat \alpha}
\end{equation*}

\begin{equation*}
\sum_{j,k,\alpha} U_{\hat i,\alpha}V_{j,\alpha}W_{k,\alpha}V_{j,\hat \alpha}
W_{k,\hat \alpha}= \sum_{\alpha} U_{\hat i,\alpha}(\sum_{j}V_{j,\alpha}
V_{j,\hat \alpha}) (\sum_{k}W_{k,\alpha}W_{k,\hat \alpha})
\end{equation*}

обозначим через M_{\alpha,\hat \alpha}

\begin{equation*}
M_{\alpha,\hat \alpha} = (\sum_{j}V_{j,\alpha}
V_{j,\hat \alpha}) (\sum_{k}W_{k,\alpha}W_{k,\hat \alpha}),
\end{equation*}
 
тогда
\begin{equation*}
\sum_{\alpha} U_{\hat i, \alpha}M_{\alpha,\hat \alpha} = 
\sum_{j,k} A_{\hat i,j,k}V_{j, \hat \alpha}W_{k,\hat \alpha}
\end{equation*}


обозначим через F_{i,\hat \alpha} правую часть. Имеем:


\begin{equation}
\sum_{\alpha} U_{\hat i, \alpha}M_{\alpha,\hat \alpha}=F_{i,\hat \alpha}
\end{equation}

Где M \in 
* Реализация на Python
** Критерий остановки 
* Численные эксперименты
 В данном параграфе будут изложены в графическом виде результаты работы программы, реализующей метод ALS. 
В качестве входных данных подавались:
 - Размерность тензора $d$ = 3
 - Ранг $r$ переменный
 - Размерности мод $dimension_i$ переменные
** Численные эксперименты для случайных тензоров
 В качестве входного тензора подается тензор, случайным образом полученный программно (с помощью процедуры
gettensor) наперед заданного ранга и размерностей мод. 

Первый цикл экспериментов призван был установить характер поведения нормы невязки 
\begin{equation}\label{curs:eq2}
max|A(i_1,i_2,i_3)-Approximation(i_1,i_2,i_3)|
\end{equation}

где Approximation(i_1,i_2,i_3) --- аппроксимация заданного тензора, построенная с помощью алгоритма
ALS, реализованного на Python.

Ниже приводятся графики поведения нормы невязки  в зависимости от числа итераций. 

- Для случайного тензора ранга $r$ = 5
#+begin_src python :exports results :results output raw
from test import *
from numpy import *
from pylab import *
d=3
dimension=[32,32,32]
r=5
a,u0=randomtensor(r,dimension,size(dimension))
eps=1e-6
a1, u,no=ALSproc(a,d,r,dimension,eps)
plot(no)
xlabel('Iterations')
ylabel('Norm')
title('Graphic of norm')
fname="rnd5.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src

#+results:
| file:rnd5.pdf |




- Для случайного тензора ранга $r$ = 10

На этом примере метод попал в локальный минимум функционала (\eq2), вследствии чего невязка убывает медленно почти
на всем протяжении времени работы алгоритма. Однако миновав локальный минимум, метод сошелся очень быстро.
#+attr_latex: width=8cm
#+name: pic1
#+begin_src python :exports results :results output raw
from test import *
from numpy import *
from pylab import *
d=3
dimension=[32,32,32]
r=10
a,u0=randomtensor(r,dimension,size(dimension))
eps=1e-6
a1,u,no=ALSproc(a,d,r,dimension,eps)
plot(no)
xlabel('Iterations')
ylabel('Norm')
title('Graphic of norm')
fname="rnd10.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src

- Для случайного тензора ранга $r$ = 25
#+attr_latex: width=8cm
#+begin_src python :exports results :results output raw
from test import *
from numpy import *
from pylab import *
d=3
dimension=[32,32,32]
r=25
a,u0=randomtensor(r,dimension,size(dimension))
eps=1e-6
a1,u,no=ALSproc(a,d,r,dimension,eps)
plot(no)
xlabel('Iterations')
ylabel('Norm')
title('Graphic of norm')
fname="rnd25.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src

- Для случайного тензора ранга $r$ = 100
#+attr_latex: width=8cmn
#+begin_src python :exports results :results output raw
from test import *
from numpy import *
from pylab import *
d=3
dimension=[32,32,32]
r=100
a,u0=randomtensor(r,dimension,size(dimension))
eps=1e-6
a1,u,no=ALSproc(a,d,r,dimension,eps)
plot(no)
xlabel('Iterations')
ylabel('Norm')
title('Graphic of norm')
fname="rnd100.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src


Несмотря на то, что скорость убывания невязки может варьироваться в зависимости от ранга и начального приближения,
невязка убывает монотонно.

Следующая серия экспериментов показывает нрафическую зависимость времени выполнения программы от:
- ранга $r$ при фиксированных размерностях тензора
 

#+attr_latex: width=8cm
#+name: "Ранг" 
#+begin_src python :exports results :results output raw
from test import *
from numpy import *
from pylab import *
from time import *
d=3
dimension=[32,32,32]
r=[2,3,5,10,20,50,100]
mar=zeros((2,7))
for i in xrange(0,7):
  t=time()
  a,u0=randomtensor(r[i],dimension,size(dimension))
  eps=1e-6
  a1,u,no=ALSproc(a,d,r[i],dimension,eps)
  mar[0,i]=time()-t
  mar[1,i]=r[i]
plot(mar[1],mar[0])
xlabel('rank')
ylabel('time')
title('Graphic of time')
fname="rnd5.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src

#+results:
: None

в ходе этого эксперимента размерности мод $dimension_i$ брались равными между собой и равными 32 а ранг 
менялся $r$ = 2,3,5,10,25,50,100,500. Исходя из графика, можно сделать вывод, что время зависит от ранга 
как O(r)
  
- размерностей тензора $dimension_i$ (i = 1,\ldots,3) при фиксированном ранге
  Эта серия экспериментов проводилась с целью изучения зависимости времени выполнения программы от размерностей мод
$dimension_i$ = 32,64,128,250,500 и ранге $r$ = 5.


#+attr_latex: width=8cm
#+name: "Ранг" 
#+begin_src python :exports results :results output raw
from test import *
from numpy import *
from pylab import *
from time import *
d=3
tempor=[16,32,64,128,250,500]

r=5
mar=zeros((2,7))
for i in xrange(0,7):
  dimension=[tempor[i],tempor[i],tempor[i]]
  t=time()
  a,u0=randomtensor(r,dimension,size(dimension))
  eps=1e-6
  a1,u,no=ALSproc(a,d,r,dimension,eps)
  mar[0,i]=time()-t
  mar[1,i]=r[i]
plot(mar[1],mar[0])
xlabel('dimension')
ylabel('time')
title('Graphic of time')
fname="rnd88.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src

Судя по графику время выполнения программы пропорционально O(n^{1.2})

** Эксперименты над неслучайными тензорами

В ходе этой серии экспериментов на вход подавался тензор размерности $d$ = 3 вида:
\begin{equation>}*
A[i,j,k] = \frac{1}{i+j+k+1}  , i,j,k =1,2,\ldots, $dimension$ - 1
\end{equation}

#+begin_src python :exports results :results output raw :cashe yes
from test import *
from numpy import *
from pylab import *
d=3
dimension=[32,32,32]
r=5
a=zeros(dimension)
for i in xrange(0,dimension[0]):
  for j in xrange(0,dimension[1]):
    for k in xrange(0,dimension[2]):
    	a[i,j,k]=1.0/(i+j+k+1)

eps=1e-6
a1, u,no=ALSproc(a,d,r,dimension,eps)
plot(no)
xlabel('Iterations')
ylabel('Norm')
title('Graphic of norm')
fname="rnd5.pdf"
savefig(fname)
#clf()
print "[[file:%s]]" % fname
#+end_src

#+results:

